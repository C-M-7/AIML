{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    result = {}\n",
    "    class_values = set(y_train) # Isse hum sb trh ki class values le skte hain kyunki apun ne set use kra hua mtlb basically jo answer hoega wo vli values\n",
    "    for current_class in class_values:\n",
    "        result[current_class] = {} # Isme humne unn classes ko features allot krdiye jo x_train ki headings thi na wo wli\n",
    "        result[\"total_data\"] = len(y_train)\n",
    "        current_class_rows = (y_train == current_class) # Ye mere tb kaam aana jb merko uss current class ki total values chiye mtlb ki wo class kidr kidr aari\n",
    "        x_train_current = x_train[current_class_rows] # isme hume vo x_train ki rows milengi jisme hmaari current class hogi\n",
    "        y_train_current = y_train[current_class_rows]\n",
    "        num_features = x_train.shape[1] # Isse hum saare features ka pta kr skte basically x_train ke columns ki count hai ye\n",
    "        result[current_class][\"total_count\"] = len(y_train_current) # kitni baar ek class ki rows aayi hain \n",
    "        for j in range(1,num_features + 1):\n",
    "            result[current_class][j] = {} # Ab isme jo apni uss feature ki values hai na jaise ki agr feature hai SALARY to values ho jaani Low, Mid, High\n",
    "            all_possible_values = set(x_train[:,j - 1]) # isse maine uss current feature ki saari values nikaal li\n",
    "            for current_value in all_possible_values:\n",
    "                result[current_class][j][current_value] = (x_train_current[:,j - 1] == current_value).sum()\n",
    "   \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hum log isliye use kr re kyunki bina log ke output ki values kaafi chhoti bhi ho skti hain\n",
    "def probability(dictonary, x, current_class):\n",
    "    output = np.log(dictonary[current_class][\"total_count\"]) - np.log(dictonary[\"total_data\"]) # ye maine class ki probability nikaal li mtlb P(y = ai)\n",
    "    num_features = len(dictonary[current_class].keys()) - 1 \n",
    "    for j in range(1, num_features+1):\n",
    "        xj = x[j - 1] # uss particular feature ki ye particular value eg salary ki high value\n",
    "        count_current_class_with_value_xj = dictonary[current_class][j][xj] + 1 # +1 for LAPLACE CORRECTION\n",
    "        count_current_class = dictonary[current_class][\"total_count\"] + len(dictonary[current_class][j].keys()) # isme v laplace lgaa hai aur + ke baad maine saare features ka count liya hai\n",
    "        current_xj_probability = np.log(count_current_class_with_value_xj) - np.log(count_current_class)\n",
    "        output = output + current_xj_probability\n",
    "    return output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSinglePoint(dictonary, x):\n",
    "    classes = dictonary.keys() # Merko saari classes chiye hogi na joki dict ki keys mai rkhi pdi hain\n",
    "    best_p = -1000 # At last merko best prob chiye na uss x ke liye\n",
    "    best_class = -1\n",
    "    first_turn = True\n",
    "    for current_class in classes:\n",
    "        if(current_class == \"total_data\"):\n",
    "            continue\n",
    "        p_current_class = probability(dictonary,x,current_class)\n",
    "        if(first_turn or p_current_class > best_p):\n",
    "            best_p = p_current_class\n",
    "            best_class = current_class\n",
    "        first_turn = False\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dictonary, x_test): # Ek predict function to bnana hee pdega na\n",
    "    y_pred = [] \n",
    "    for x in x_test:\n",
    "        x_class = predictSinglePoint(dictonary, x) # mai x_test ki hr value pe jaake uski probability nikaalunga \n",
    "        y_pred.append(x_class)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kuch ni isme bss hum iris dataset ko categorise kr re kyunki apun ne saara model classes ke liye likha na isliye\n",
    "# isme iris ke mean ke hisab se uske cols ko categorize kr re\n",
    "def makeLabelled(column):\n",
    "    second_limit = column.mean()\n",
    "    first_limit = 0.5 * second_limit\n",
    "    third_limit = 1.5*second_limit\n",
    "    for i in range (0,len(column)):\n",
    "        if (column[i] < first_limit):\n",
    "            column[i] = 0\n",
    "        elif (column[i] < second_limit):\n",
    "            column[i] = 1\n",
    "        elif(column[i] < third_limit):\n",
    "            column[i] = 2\n",
    "        else:\n",
    "            column[i] = 3\n",
    "    return column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,X.shape[-1]):\n",
    "    X[:,i] = makeLabelled(X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train,X_test,Y_train,Y_test = model_selection.train_test_split(X,Y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = fit(X_train,Y_train)\n",
    "Y_pred = predict(dictionary,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.94      1.00      0.97        16\n",
      "           2       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.98      0.96      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n",
      "[[13  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  1  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        13\n",
      "           1       0.76      1.00      0.86        16\n",
      "           2       1.00      0.67      0.80         9\n",
      "\n",
      "    accuracy                           0.87        38\n",
      "   macro avg       0.92      0.84      0.86        38\n",
      "weighted avg       0.90      0.87      0.87        38\n",
      "\n",
      "[[11  2  0]\n",
      " [ 0 16  0]\n",
      " [ 0  3  6]]\n"
     ]
    }
   ],
   "source": [
    "# kuch ni sun jaise apun ne iris ko mean ke hisaab se categorise kra tha na vaise hee ek sklearn ki inbuilt function hai jisko Gaussian Classifier bolte hain wo use kra hua\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
